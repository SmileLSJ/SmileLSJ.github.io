---
layout:     post
title:      "Netty-02-编解码"
date:       2021-09-22 12:00:00
author:     "LSJ"
header-img: "img/post-bg-2015.jpg"
tags:
    - 拉钩
    - Netty
    - 拉钩Netty
---



Netty的经典实用：蚂蚁的SoFABolt 

网址：https://github.com/sofastack/sofa-bolt





##  编解码技术

* 为什么有拆包和粘包

  * 在网络通信的过程中，每次可以发送的数据包大小是受多种因素限制的，如 MTU 传输单元大小、MSS 最大分段大小、滑动窗口等。如果一次传输的网络包数据大小超过传输单元大小，那么我们的数据可能会拆分为多个数据包发送出去

* MTU和MSS

  * MTU（Maxitum Transmission Unit） 是链路层一次最大传输数据的大小。MTU 一般来说大小为 1500 byte
  * MSS（Maximum Segement Size） 是指 TCP 最大报文段长度，它是传输层一次发送最大数据的大小

  ![Drawing 1.png](/img/CgqCHl-iZjqAVNpwAAC-5hm9AJA479.png)

  * MTU 和 MSS 一般的计算关系为：MSS = MTU - IP 首部 - TCP首部，如果 MSS + TCP 首部 + IP 首部 > MTU，那么数据包将会被拆分为多个发送。这就是拆包现象。

* 滑动窗口
  * 滑动窗口是 TCP 传输层用于流量控制的一种有效措施，也被称为通告窗口。滑动窗口是数据接收方设置的窗口大小，随后接收方会把窗口大小告诉发送方，以此限制发送方每次发送数据的大小，从而达到流量控制的目的

* Nagle算法
  * 用于解决频繁发送小数据包而带来的网络拥塞问题
  * 可以理解为批量发送



### 拆包和粘包

* 情况

  ![Drawing 3.png](/img/CgqCHl-iZk2ALa_sAAD704YRY80575.png)
  * 服务端恰巧读到了两个完整的数据包 A 和 B，没有出现拆包/粘包问题；
  * 服务端接收到 A 和 B 粘在一起的数据包，服务端需要解析出 A 和 B；
  * 服务端收到完整的 A 和 B 的一部分数据包 B-1，服务端需要解析出完整的 A，并等待读取完整的 B 数据包；
  * 服务端接收到 A 的一部分数据包 A-1，此时需要等待接收到完整的 A 数据包；
  * 数据包 A 较大，服务端需要多次才可以接收完数据包 A。

* 问题
  * 由于拆包/粘包问题的存在，数据接收方很难界定数据包的边界在哪里，很难识别出一个完整的数据包
* 解决方法
  * 定义应用层的通信协议





#### 方案一：消息长度固定

* 原理：
  * 每个数据报文都需要一个固定的长度。当接收方累计读取到固定长度的报文后，就认为已经获得一个完整的消息。当发送方的数据小于固定长度时，则需要空位补齐。
* 优点
  * 使用简单，因为特定好，几个字段表示一个完整的报文
* 缺点
  * 无法很好设定固定长度的值，如果长度太大会造成字节浪费，长度太小会影响消息传输，一般此方案不采用



#### 方案二：特殊分割符

* 既然接收方无法区分消息的边界，那么我们可以在每次发送报文的尾部加上特定分隔符，接收方就可以根据特殊分隔符进行消息拆分。以下报文根据特定分隔符 \n 按行解析，即可得到 AB、CDEF、GHIJ、K、LM 五条原始报文。

  ```
  +-------------------------+
  | AB\nCDEF\nGHIJ\nK\nLM\n |
  +-------------------------+
  ```

* 好处
  * 使用简单，高效，特定分隔符法在消息协议足够简单的场景下比较高效，例如大名鼎鼎的 Redis 在通信过程中采用的就是换行分隔符
* 最好的做法
  * 由于在发送报文时尾部需要添加特定分隔符，所以对于分隔符的选择一定要避免和消息体中字符相同，以免冲突。否则可能出现错误的消息拆分。比较推荐的做法是将消息进行编码，例如 base64 编码，然后可以选择 64 个编码字符之外的字符作为特定分隔符





#### 方案三：消息长度+消息内容

```
消息头     消息体
+--------+----------+
| Length |  Content |
+--------+----------+
```

* **消息长度 + 消息内容**是项目开发中最常用的一种协议，如上展示了该协议的基本格式。消息头中存放消息的总长度，例如使用 4 字节的 int 值记录消息的长度，消息体实际的二进制的字节数据。接收方在解析数据时，首先读取消息头的长度字段 Len，然后紧接着读取长度为 Len 的字节数据，该数据即判定为一个完整的数据报文。依然以上述提到的原始字节数据为例，使用该协议进行编码后的结果如下所示：

  ```
  +-----+-------+-------+----+-----+
  | 2AB | 4CDEF | 4GHIJ | 1K | 2LM |
  +-----+-------+-------+----+-----+
  ```

  * 消息长度 + 消息内容的使用方式非常灵活，且不会存在消息定长法和特定分隔符法的明显缺陷。当然在消息头中不仅只限于存放消息的长度，而且可以自定义其他必要的扩展字段，例如消息版本、算法类型等







## 自定义通信协议设计

* 协议目的
  * 双方能够正常通信，协议，就是通信双方事先商量好的接口暗语，在 TCP 网络编程中，发送方和接收方的数据包格式都是二进制，发送方将对象转化成二进制流发送给接收方，接收方获得二进制数据后需要知道如何解析成对象
* 自定义协议特点
  * **极致性能**：通用的通信协议考虑了很多兼容性的因素，必然在性能方面有所损失
  * **扩展性**：自定义的协议相比通用协议更好扩展，可以更好地满足自己的业务需求
  * **安全性**：通用协议是公开的，很多漏洞已经很多被黑客攻破。自定义协议更加**安全**，因为黑客需要先破解你的协议内容





### 自定义协议重要要素

#### 1. 魔数

* 魔数是通信双方协商的一个暗号，通常采用固定的几个字节表示。
* 魔数的作用是**防止任何人随便向服务器的端口上发送数据**。
  * 服务端在接收到数据时会解析出前几个固定字节的魔数，然后做正确性比对。如果和约定的魔数不匹配，则认为是非法数据，可以直接关闭连接或者采取其他措施以增强系统的安全防护。
* 魔数的思想在压缩算法、Java Class 文件等场景中都有所体现，例如 Class 文件开头就存储了魔数 0xCAFEBABE，在加载 Class 文件时首先会验证魔数的正确性



#### 2. 协议版本号

* 随着业务需求的变化，协议可能需要对结构或字段进行改动，不同版本的协议对应的解析方法也是不同的。所以在生产级项目中强烈建议预留**协议版本号**这个字段。



#### 3. 序列化算法

* 序列化算法字段表示数据发送方应该采用何种方法将请求的对象转化为二进制，以及如何再将二进制转化为对象，如 JSON、Hessian、Java 自带序列化等。



#### 4. 报文类型

* 在不同的业务场景中，报文可能存在不同的类型。例如在 RPC 框架中有请求、响应、心跳等类型的报文，在 IM 即时通信的场景中有登陆、创建群聊、发送消息、接收消息、退出群聊等类型的报文。



#### 5. 长度域字段

* 长度域字段代表**请求数据**的长度，接收方根据长度域字段获取一个完整的报文。



#### 6. 请求数据

* 请求数据通常为序列化之后得到的**二进制流**，每种请求数据的内容是不一样的。



#### 7. 状态

* 状态字段用于标识**请求是否正常**。一般由被调用方设置。例如一次 RPC 调用失败，状态字段可被服务提供方设置为异常状态。



#### 8. 保留字段

* 保留字段是可选项，为了应对协议升级的可能性，可以预留若干字节的保留字段，以备不时之需



最后的协议示例

```txt

+---------------------------------------------------------------+
| 魔数 2byte | 协议版本号 1byte | 序列化算法 1byte | 报文类型 1byte  |
+---------------------------------------------------------------+
| 状态 1byte |        保留字段 4byte     |      数据长度 4byte     | 
+---------------------------------------------------------------+
|                   数据内容 （长度不定）                          |
+---------------------------------------------------------------+

```



### 实现自定义通信协议

* Netty提供了丰富的编解码抽象类基类



#### 常用编码器类型

* MessageToByteEncoder 对象编码成字节流；
* MessageToMessageEncoder 一种消息类型编码成另外一种消息类型。



#### 常用解码器类型

* ByteToMessageDecoder/ReplayingDecoder 将字节流解码为消息对象；
* MessageToMessageDecoder 将一种消息类型解码为另外一种消息类型。



#### 一次解码器和二次解码器

* 一次解码器用于解决 TCP 拆包/粘包问题，按协议解析后得到的字节数据。其中数据还是字节
* 需要对解析后的字节数据做对象模型的转换，这时候便需要用到二次解码器，同理编码器的过程是反过来的。



##### 一次编解码器

* MessageToByteEncoder/ByteToMessageDecoder

##### 二次编解码器

* MessageToMessageEncoder/MessageToMessageDecoder





### 常用编解码器学习

#### 抽象编码类

![Drawing 0.png](/img/CgqCHl-lDlWAUGw2AAMI8fuvukI452.png)



##### MessageToByteEncoder

* 作用
  * 用于将对象编码成字节流

* MessageToByteEncoder 提供了唯一的 encode 抽象方法，我们只需要实现**encode 方法**即可完成自定义编码

* 源码

  ```java
  public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {
    ByteBuf buf = null;
  
    try {
      //1. 消息类型是否匹配
      if (this.acceptOutboundMessage(msg)) {
        I cast = msg;
        
        //2. 分配 ByteBuf 资源，默认使用堆外内存
        buf = this.allocateBuffer(ctx, msg, this.preferDirect);
  
        try {
          
          //3. 执行编码encode方法
          this.encode(ctx, cast, buf);
        } finally {
          
          //4. 向后传递写事件
          ReferenceCountUtil.release(msg);
        }
  
        if (buf.isReadable()) {
          ctx.write(buf, promise);
        } else {
          buf.release();
          ctx.write(Unpooled.EMPTY_BUFFER, promise);
        }
  
        buf = null;
      } else {
        ctx.write(msg, promise);
      }
    } catch (EncoderException var17) {
      throw var17;
    } catch (Throwable var18) {
      throw new EncoderException(var18);
    } finally {
      if (buf != null) {
        buf.release();
      }
  
    }
  
  }
  ```

* **编码器实现非常简单，不需要关注拆包和粘包问题**。下面案例展示了如何将字符串类型的数据写入到ByteBuf实例中，ByteBuf实例将传递给ChannelPipeline链表中的下一个ChannelOutboundHandler

  ```java
  public class StringToByteEncoder extends MessageToByteEncoder<String> {
          @Override
          protected void encode(ChannelHandlerContext channelHandlerContext, String data, ByteBuf byteBuf) throws Exception {
              byteBuf.writeBytes(data.getBytes());
          }
  }
  ```



##### MessageToMessageEncoder

* MessageToMessageEncoder 与 MessageToByteEncoder 类似，同样只需要实现 encode 方法

* MessageToMessageEncoder 是将一种格式的消息转换为另外一种格式的消息。其中第二个 Message 所指的可以是任意一个对象，如果该对象是 ByteBuf 类型，那么基本上和 MessageToByteEncoder 的实现原理是一致的

* MessageToMessageEncoder 常用的**实现子类**有 StringEncoder、LineEncoder、Base64Encoder 等。以 StringEncoder 为例看下 MessageToMessageEncoder 的用法。源码示例如下：将 CharSequence 类型（String、StringBuilder、StringBuffer 等）转换成 ByteBuf 类型，结合 StringDecoder 可以直接实现 String 类型数据的编解码。

  ```java
  public class StringEncoder extends MessageToMessageEncoder<CharSequence> {
      private final Charset charset;
  
      public StringEncoder() {
          this(Charset.defaultCharset());
      }
  
      public StringEncoder(Charset charset) {
          if (charset == null) {
              throw new NullPointerException("charset");
          } else {
              this.charset = charset;
          }
      }
  
      protected void encode(ChannelHandlerContext ctx, CharSequence msg, List<Object> out) throws Exception {
          if (msg.length() != 0) {
              out.add(ByteBufUtil.encodeString(ctx.alloc(), CharBuffer.wrap(msg), this.charset));
          }
      }
  }
  ```

  

#### 抽象解码类

![Drawing 1.png](/img/CgqCHl-lDmiAU8l2AAPWlIx6BfA268.png)

* 解码类是 ChanneInboundHandler 的抽象类实现，操作的是 Inbound 入站数据。
* 解码器实现的难度要远大于编码器，**因为解码器需要考虑拆包/粘包问题，因为发送时是一个对象，但是经过网络传输就会被拆包**。由于接收方有可能没有接收到完整的消息，所以解码框架需要对入站的数据做缓冲操作，直至获取到完整的消息。



##### ByteToMessageDecoder

* 抽象方法

  ```java
  public abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter {
        protected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception;
    
      protected void decodeLast(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {
          if (in.isReadable()) {
              // Only call decode() if there is something left in the buffer to decode.
              // See https://github.com/netty/netty/issues/4386
              decodeRemovalReentryProtection(ctx, in, out);
          }
      }
  }
  ```

* decode() 是用户必须实现的抽象方法，在该方法在调用时需要传入接收的数据 ByteBuf，及用来添加编码后消息的 List
  * 问题：由于 TCP 粘包问题，ByteBuf 中可能包含多个有效的报文，或者不够一个完整的报文
* Netty 会重复回调 decode() 方法，直到没有解码出新的完整报文可以添加到 List 当中，或者 ByteBuf 没有更多可读取的数据为止。如果此时 List 的内容不为空，那么会传递给 ChannelPipeline 中的下一个ChannelInboundHandler
* decodeLast
  * **为什么抽象解码器要比编码器多一个 decodeLast() 方法呢**？
    * 因为 decodeLast 在 Channel 关闭后会被调用一次，主要用于处理 ByteBuf 最后剩余的字节数据。Netty 中 decodeLast 的默认实现只是简单调用了 decode() 方法。如果有特殊的业务需求，则可以通过重写 decodeLast() 方法扩展自定义逻辑。



##### **MessageToMessageDecoder**

* MessageToMessageDecoder 与 ByteToMessageDecoder 作用类似，都是将一种消息类型的编码成另外一种消息类型。

* 与 ByteToMessageDecoder **不同的是 MessageToMessageDecoder 并不会对数据报文进行缓存，它主要用作转换消息模型**。

* 比较推荐的做法是使用 **ByteToMessageDecoder 解析 TCP 协议，解决拆包/粘包问题**。解析得到有效的 ByteBuf 数据，然后传递给后续的 MessageToMessageDecoder 做数据对象的转换，具体流程如下图所示

  ![Lark20201109-102121.png](/img/CgqCHl-op8iAMMV_AAH0Z4-w0bM373.png)

### 通信协议实战

* 解决问题

  * 如何判断ByteBuf是否存在完整的报文？？？
    * 最常用的就是通过读取消息长度dataLength进行判断
      * 如果ByteBuf的可读数据长度小于dataLength，说明ByteBuf还不够获取一个完整的报文。在该协议前面的协议头部分包含了魔数，协议版本号，数据长度等固定长度，共14个字节。固定字段长度和数据长度可以作为我们判断消息完整性的依据

* 源码

  ```java
  /*
  +---------------------------------------------------------------+
  | 魔数 2byte | 协议版本号 1byte | 序列化算法 1byte | 报文类型 1byte  |
  +---------------------------------------------------------------+
  | 状态 1byte |        保留字段 4byte     |      数据长度 4byte     | 
  +---------------------------------------------------------------+
  |                   数据内容 （长度不定）                          |
  +---------------------------------------------------------------+
   */
  @Override
  public final void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) {
      // 判断 ByteBuf 可读取字节
      if (in.readableBytes() < 14) { 
          return;
      }
      in.markReaderIndex(); // 标记 ByteBuf 读指针位置
      in.skipBytes(2); // 跳过魔数
      in.skipBytes(1); // 跳过协议版本号
      byte serializeType = in.readByte();
      in.skipBytes(1); // 跳过报文类型
      in.skipBytes(1); // 跳过状态字段
      in.skipBytes(4); // 跳过保留字段
      int dataLength = in.readInt();
      if (in.readableBytes() < dataLength) {
          in.resetReaderIndex(); // 重置 ByteBuf 读指针位置
          return;
      }
      byte[] data = new byte[dataLength];
      in.readBytes(data);
      SerializeService serializeService = getSerializeServiceByType(serializeType);
      Object obj = serializeService.deserialize(data);
      if (obj != null) {
          out.add(obj);
      }
  }
  ```




## 常用解码器

* 因为涉及到解码，还有拆包和粘包的问题，所以单独搞一波。



### 固定长度解码器 FixedLengthFrameDecoder

* 固定长度解码器 FixedLengthFrameDecoder 非常简单，直接通过构造函数设置固定长度的大小 frameLength，无论接收方一次获取多大的数据，都会严格按照 frameLength 进行解码。

  * 如果累积读取到长度大小为 frameLength 的消息，那么解码器认为已经获取到了一个完整的消息。
  * 如果消息长度小于 frameLength，FixedLengthFrameDecoder 解码器会一直等后续数据包的到达，直至获得完整的消息。

  

### 特殊分隔符解码器 DelimiterBasedFrameDecoder

* 特殊属性
  * delimeters：
    * 特殊分隔符，通过写入ByteBuf作为参数传入。delimiters 的类型是 ByteBuf 数组，所以我们可以同时指定多个分隔符，但是最终会选择长度最短的分隔符进行消息拆分
  * maxlength：
    * maxLength 是报文最大长度的限制。如果超过 maxLength 还没有检测到指定分隔符，将会抛出 TooLongFrameException。可以说 maxLength 是对程序在极端情况下的一种保护措施
  * failFast：
    * failFast 与 maxLength 需要搭配使用，通过设置 failFast 可以控制抛出 TooLongFrameException 的时机，可以说 Netty 在细节上考虑得面面俱到。
      * 如果 failFast=true，那么在超出 maxLength 会立即抛出 TooLongFrameException，不再继续进行解码。
      * 如果 failFast=false，那么会等到解码出一个完整的消息后才会抛出 TooLongFrameException。
  * stripDelimiter
    * stripDelimiter 的作用是判断解码后得到的消息是否去除分隔符。



### 长度域解码器 LengthFieldBasedFrameDecoder

* 长度域解码器 LengthFieldBasedFrameDecoder 是解决 TCP 拆包/粘包问题最常用的**解码器。**

* 它基本上可以覆盖大部分基于长度拆包场景，开源消息中间件 RocketMQ 就是使用 LengthFieldBasedFrameDecoder 进行解码的

* 重要属性

  * 特有属性

    ```java
    // 长度字段的偏移量，也就是存放长度数据的起始位置
    private final int lengthFieldOffset; 
    // 长度字段所占用的字节数
    private final int lengthFieldLength; 
    /*
     * 消息长度的修正值
     *
     * 在很多较为复杂一些的协议设计中，长度域不仅仅包含消息的长度，而且包含其他的数据，如版本号、数据类型、数据状态等，那么这时候我们需要使用 lengthAdjustment 进行修正
     * 
     * lengthAdjustment = 包体的长度值 - 长度域的值
     *
     */
    private final int lengthAdjustment; 
    // 解码后需要跳过的初始字节数，也就是消息内容字段的起始位置
    private final int initialBytesToStrip;
    // 长度字段结束的偏移量，lengthFieldEndOffset = lengthFieldOffset + lengthFieldLength
    private final int lengthFieldEndOffset;
    ```

    

  * 其他解码器（如特定分隔符解码器）的相似的属性

    ```java
    private final int maxFrameLength; // 报文最大限制长度
    private final boolean failFast; // 是否立即抛出 TooLongFrameException，与 maxFrameLength 搭配使用
    private boolean discardingTooLongFrame; // 是否处于丢弃模式
    private long tooLongFrameLength; // 需要丢弃的字节数
    private long bytesToDiscard; // 累计丢弃的字节数
    ```

* 示例1：典型的基于消息长度+消息内容的解码

  ```txt
  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)
  +--------+----------------+      +--------+----------------+
  | Length | Actual Content |----->| Length | Actual Content |
  | 0x000C | "HELLO, WORLD" |      | 0x000C | "HELLO, WORLD" |
  +--------+----------------+      +--------+----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 0，因为 Length 字段就在报文的开始位置。
    * lengthFieldLength = 2，协议设计的固定长度。
    * lengthAdjustment = 0，Length 字段只包含消息长度，不需要做任何修正。
    * initialBytesToStrip = 0，解码后内容依然是 Length + Content，不需要跳过任何初始字节。

* 示例2：解码结果需要截断

  ```txt
  BEFORE DECODE (14 bytes)         AFTER DECODE (12 bytes)
  +--------+----------------+      +----------------+
  | Length | Actual Content |----->| Actual Content |
  | 0x000C | "HELLO, WORLD" |      | "HELLO, WORLD" |
  +--------+----------------+      +----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 0，因为 Length 字段就在报文的开始位置。
    * lengthFieldLength = 2，协议设计的固定长度。
    * lengthAdjustment = 0，Length 字段只包含消息长度，不需要做任何修正。
    * initialBytesToStrip = 2，跳过 Length 字段的字节长度，解码后 ByteBuf 中只包含 Content字段。

* 示例3：长度字段包含消息长度和消息内容所占的字节。

  ```txt
  BEFORE DECODE (14 bytes)         AFTER DECODE (14 bytes)
  +--------+----------------+      +--------+----------------+
  | Length | Actual Content |----->| Length | Actual Content |
  | 0x000E | "HELLO, WORLD" |      | 0x000E | "HELLO, WORLD" |
  +--------+----------------+      +--------+----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 0，因为 Length 字段就在报文的开始位置。
    * lengthFieldLength = 2，协议设计的固定长度。
    * lengthAdjustment = -2，长度字段为 14 字节，需要减 2 才是拆包所需要的长度。
    * initialBytesToStrip = 0，解码后内容依然是 Length + Content，不需要跳过任何初始字节。

* 示例4：基于长度字段偏移的解码。

  ```txt
  BEFORE DECODE (17 bytes)                      AFTER DECODE (17 bytes)
  +----------+----------+----------------+      +----------+----------+----------------+
  | Header 1 |  Length  | Actual Content |----->| Header 1 |  Length  | Actual Content |
  |  0xCAFE  | 0x00000C | "HELLO, WORLD" |      |  0xCAFE  | 0x00000C | "HELLO, WORLD" |
  +----------+----------+----------------+      +----------+----------+----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 2，需要跳过 Header 1 所占用的 2 字节，才是 Length 的起始位置。
    * lengthFieldLength = 3，协议设计的固定长度。
    * lengthAdjustment = 0，Length 字段只包含消息长度，不需要做任何修正。
    * initialBytesToStrip = 0，解码后内容依然是完整的报文，不需要跳过任何初始字节。

* 示例5：长度字段与内容字段不再相邻

  ```txt
  BEFORE DECODE (17 bytes)                      AFTER DECODE (17 bytes)
  +----------+----------+----------------+      +----------+----------+----------------+
  |  Length  | Header 1 | Actual Content |----->|  Length  | Header 1 | Actual Content |
  | 0x00000C |  0xCAFE  | "HELLO, WORLD" |      | 0x00000C |  0xCAFE  | "HELLO, WORLD" |
  +----------+----------+----------------+      +----------+----------+----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 0，因为 Length 字段就在报文的开始位置。
    * lengthFieldLength = 3，协议设计的固定长度。
    * lengthAdjustment = 2，由于 Header + Content 一共占用 2 + 12 = 14 字节，所以 Length 字段值（12 字节）加上 lengthAdjustment（2 字节）才能得到 Header + Content 的内容（14 字节）。
    * initialBytesToStrip = 0，解码后内容依然是完整的报文，不需要跳过任何初始字节。

* 示例 6：基于长度偏移和长度修正的解码。

  ```txt
  BEFORE DECODE (16 bytes)                       AFTER DECODE (13 bytes)
  +------+--------+------+----------------+      +------+----------------+
  | HDR1 | Length | HDR2 | Actual Content |----->| HDR2 | Actual Content |
  | 0xCA | 0x000C | 0xFE | "HELLO, WORLD" |      | 0xFE | "HELLO, WORLD" |
  +------+--------+------+----------------+      +------+----------------+
  ```

  * 对应的特有属性的值
    * lengthFieldOffset = 1，需要跳过 HDR1 所占用的 1 字节，才是 Length 的起始位置。
    * lengthFieldLength = 2，协议设计的固定长度。
    * lengthAdjustment = 1，由于 HDR2 + Content 一共占用 1 + 12 = 13 字节，所以 Length 字段值（12 字节）加上 lengthAdjustment（1）才能得到 HDR2 + Content 的内容（13 字节）。
    * initialBytesToStrip = 3，解码后跳过 HDR1 和 Length 字段，共占用 3 字节。

* 示例7：长度字段包含除 Content 外的多个其他字段。

  ```txt
  BEFORE DECODE (16 bytes)                       AFTER DECODE (13 bytes)
  +------+--------+------+----------------+      +------+----------------+
  | HDR1 | Length | HDR2 | Actual Content |----->| HDR2 | Actual Content |
  | 0xCA | 0x0010 | 0xFE | "HELLO, WORLD" |      | 0xFE | "HELLO, WORLD" |
  +------+--------+------+----------------+      +------+----------------+
  ```

  * 对应的特有属性的值

    * lengthFieldOffset = 1，需要跳过 HDR1 所占用的 1 字节，才是 Length 的起始位置。

      lengthFieldLength = 2，协议设计的固定长度。

      lengthAdjustment = -3，Length 字段值（16 字节）需要减去 HDR1（1 字节） 和 Length 自身所占字节长度（2 字节）才能得到 HDR2 和 Content 的内容（1 + 12 = 13 字节）。

      initialBytesToStrip = 3，解码后跳过 HDR1 和 Length 字段，共占用 3 字节。



## 编解码之后的发送流程

### Pipeline事件传播

* 根据网络数据的流向，ChannelPipeline 分为入站 ChannelInboundHandler 和出站 ChannelOutboundHandler 两种处理器

  ![图片11.png](/img/Ciqc1F-uZy-Ae5ElAANEp703VGM268.png)

  
  * 当我们从客户端向服务端发送请求，或者服务端向客户端响应请求结果都属于出站处理器 ChannelOutboundHandler 的行为，所以当我们调用 writeAndFlush 时，数据一定会在 Pipeline 中进行传播。



### writeAndFlush事件传播分析

#### Outbound的传播

* 当出站的处理器调用了writeAndFlush，执行了什么？？？？

* 通过源码定位，找到了AbstractChannelHandlerContext的write方法

  * 确认下方法的入参，因为我们需要执行 flush 动作，所以 flush == true；
  * write 方法还需要 ChannelPromise 参数，可见写操作是个异步的过程。AbstractChannelHandlerContext 会默认初始化一个 ChannelPromise 完成该异步操作，ChannelPromise 内部持有当前的 Channel 和 EventLoop，此外你可以向 ChannelPromise 中注册回调监听 listener 来获得异步操作的结果

  ```java
  private void write(Object msg, boolean flush, ChannelPromise promise) {
    //....非核心部分....
    
    //1. 找到Pipeline链表中下一个Outbound类型的ChannelHandler节点
    final AbstractChannelHandlerContext next = findContextOutbound(flush ?
                                                                   (MASK_WRITE | MASK_FLUSH) : MASK_WRITE);
    final Object m = pipeline.touch(msg, next);
    EventExecutor executor = next.executor();
    
    //2. 判断当前线程是否是NioEventLoop中的线程
    if (executor.inEventLoop()) {
      if (flush) {
        next.invokeWriteAndFlush(m, promise);
      } else {
        next.invokeWrite(m, promise);
      }
    } else {
      final AbstractWriteTask task;
      if (flush) {
        task = WriteAndFlushTask.newInstance(next, m, promise);
      }  else {
        task = WriteTask.newInstance(next, m, promise);
      }
      if (!safeExecute(executor, task, promise, m)) {
        // We failed to submit the AbstractWriteTask. We need to cancel it so we decrement the pending bytes
        // and put it back in the Recycler for re-use later.
        //
        // See https://github.com/netty/netty/issues/8343.
        task.cancel();
      }
    }
  }
  ```

  * 第一步，调用 findContextOutbound 方法找到 Pipeline 链表中下一个 Outbound 类型的 ChannelHandler。在我们模拟的场景中下一个 Outbound 节点是 ResponseSampleEncoder
  * 第二步，通过 inEventLoop 方法判断当前线程的身份标识，
    * 如果当前线程和 EventLoop 分配给当前 Channel 的线程是同一个线程的话，那么所提交的任务将被立即执行。
    * 否则当前的操作将被封装成一个 Task 放入到 EventLoop 的任务队列，稍后执行。所以 **writeAndFlush 是否是线程安全的呢？多个线程处理，肯定不是线程安全的**
  * 第三步，因为 flush== true，将会直接执行 next.invokeWriteAndFlush(m, promise) 这行代码，我们跟进去源码。。发现最终会它会执行下一个 ChannelHandler 节点的 write 方法，那么流程又回到了 到 AbstractChannelHandlerContext 中重复执行 write 方法，继续寻找下一个 Outbound 节点

* 重写MessageToByteEncoder方法时，那通过上面的分析应该是Outbound节点的write方法，为何只是重写了encoder方法，因为实现编码器的时候都会继承MessageToByteEncoder抽象类，MessageToByteEncoder 重写了 ChanneOutboundHandler 的 write 方法，其中会调用子类实现的 encode 方法完成数据编码
* Outbound的节点调用链路：
  * 在Pipeline中一直寻找Outbound节点，并向前传播，直到Head节点结束。由Head节点完成最后的数据发送





#### 写Buffer对象

* 上面经过了多个Outbound节点，那么最后数据是如何写到Socket底层，然后进行通信的呢？？？

  * 从上面直到，最后由Head节点完成数据最后的发送，那么Head节点对于发送至关重要

* HeadContext节点

  ```java
  final class HeadContext extends AbstractChannelHandlerContext
    implements ChannelOutboundHandler, ChannelInboundHandler {
  
    //省略不重要的代码
  
    @Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
      
      //最后定位到 AbstractChannel # AbstractUnsafe # write方法
      unsafe.write(msg, promise);
    }
    
  }
  ```

* AbstractChannel # AbstractUnsafe # write

  ```java
  @Override
  public final void write(Object msg, ChannelPromise promise) {
    assertEventLoop();
  
    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
    if (outboundBuffer == null) {
      
      safeSetFailure(promise, newClosedChannelException(initialCloseCause));
      // release message now to prevent resource-leak
      ReferenceCountUtil.release(msg);
      return;
    }
  
    int size;
    try {
      
      //1. 过滤消息
      msg = filterOutboundMessage(msg);
      size = pipeline.estimatorHandle().size(msg);
      if (size < 0) {
        size = 0;
      }
    } catch (Throwable t) {
      safeSetFailure(promise, t);
      ReferenceCountUtil.release(msg);
      return;
    }
  
    //2. 向 ChannelOutboundBuffer 中添加数据
    outboundBuffer.addMessage(msg, size, promise);
  }
  ```

  * filterOutboundMessage 方法会对待写入的 msg 进行过滤，如果 msg 使用的不是 DirectByteBuf，那么它会将 msg 转换成 DirectByteBuf
  * ChannelOutboundBuffer 可以理解为一个缓存结构，从源码最后一行 outboundBuffer.addMessage 可以看出是在向这个缓存中添加数据，所以 ChannelOutboundBuffer 才是理解数据发送的关键

*  ChannelOutboundBuffer # addMessage

  ```java
  public void addMessage(Object msg, int size, ChannelPromise promise) {
    Entry entry = Entry.newInstance(msg, size, total(msg), promise);
    if (tailEntry == null) {
      flushedEntry = null;
    } else {
      Entry tail = tailEntry;
      tail.next = entry;
    }
    tailEntry = entry;
    if (unflushedEntry == null) {
      unflushedEntry = entry;
    }
  
    //判断缓存的水位线，怎么理解，就可以理解为是否可以在写入此缓存中
    incrementPendingOutboundBytes(entry.pendingSize, false);
  }
  ```

  * ChannelOutboundBuffer 缓存是一个链表结构，每次传入的数据都会被封装成一个 Entry 对象添加到链表中。ChannelOutboundBuffer 包含**三个非常重要的指针**：

    * 第一个被写到缓冲区的**节点 flushedEntry**、
    * 第一个未被写到缓冲区的**节点 unflushedEntry**
    * 最后一个**节点 tailEntry。**

  * 三个指针的关系

    ![图片13.png](/img/CgqCHl-uZ1GADbu0AAMyHCydEjU371.png)

* incrementPendingOutboundBytes

  ```java
  private void incrementPendingOutboundBytes(long size, boolean invokeLater) {
    if (size == 0) {
      return;
    }
  
    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);
    
    //判断缓存大小是否超过高水位线
    if (newWriteBufferSize > channel.config().getWriteBufferHighWaterMark()) {
      setUnwritable(invokeLater);
    }
  }
  ```

  * incrementPendingOutboundBytes 的逻辑非常简单，每次添加数据时都会累加数据的字节数，然后判断缓存大小是否超过所设置的高水位线 64KB，
    * 如果超过了高水位，那么 Channel 会被设置为不可写状态。
    * 直到缓存的数据大小低于低水位线 32KB 以后，Channel 才恢复成可写状态

* 总结

  * 上面只是将数据写入到了Buffer中，那么flush动作缓存又会发生什么变化呢？？？





#### 刷新Buffer队列

* 入口 AbstractChannelHandlerContext # invokeWriteAndFlush

  ```java
  private void invokeWriteAndFlush(Object msg, ChannelPromise promise) {
    if (invokeHandler()) {
      invokeWrite0(msg, promise);
      
      //flush操作，会不断的找下一个Outbound节点，然后向前传播，最终找到Head节点，即HeadContext
      invokeFlush0();
    } else {
      writeAndFlush(msg, promise);
    }
  }
  ```

* 当执行完 write 写操作之后，invokeFlush0 会触发 flush 动作，与 write 方法类似，flush 方法同样会从 Tail 节点开始传播到 Head 节点，同样我们跟进下 HeadContext 的 flush 源码：

* HeadContext # flush

  ```java
  @Override
  public void flush(ChannelHandlerContext ctx) {
    unsafe.flush();
  }
  
  
  
  // 此方法在 AbstractChannel # flush方法
  @Override
  public final void flush() {
    assertEventLoop();
  
    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
    if (outboundBuffer == null) {
      return;
    }
  
    
    //核心方法
    outboundBuffer.addFlush();
    flush0();
  }
  ```

* ChannelOutboundBuffer # addFlush

  ```java
  public void addFlush() {
  
    Entry entry = unflushedEntry;
    if (entry != null) {
      if (flushedEntry == null) {
        // there is no flushedEntry yet, so start with the entry
        flushedEntry = entry;
      }
      do {
        flushed ++;
        if (!entry.promise.setUncancellable()) {
          
          int pending = entry.cancel();
          
          // 减去待发送的数据，如果总字节数低于低水位，那么 Channel 将变为可写状态
          decrementPendingOutboundBytes(pending, false, true);
        }
        entry = entry.next;
      } while (entry != null);
  
      
      unflushedEntry = null;
    }
  }
  ```

  * addFlush 方法同样也会操作 ChannelOutboundBuffer 缓存数据。

  * 操作过程中，缓存的指针变化？？？

    ![图片14.png](/img/CgqCHl-uZ2CAFvXuAAJkYjAgb8A346.png)

    * 此时 flushedEntry 指针有所改变，变更为 unflushedEntry 指针所指向的数据，然后 unflushedEntry 指针指向 NULL，flushedEntry 指针指向的数据才会被真正发送到 Socket 缓冲区。
    * **改变水位：**在 addFlush 源码中 decrementPendingOutboundBytes 与之前 addMessage 源码中的 incrementPendingOutboundBytes 是相对应的。decrementPendingOutboundBytes 主要作用是减去待发送的数据字节，如果缓存的大小已经小于低水位，那么 Channel 会恢复为可写状态

  

* flush0方法

  ![图片15.png](/img/Ciqc1F-uZ4iAYZDxAAROuJN6ruk510.png)

  * 调用层级很深，关键在于AbstractNioByteChannel的doWrite方法，该方法负责将数据真正写入到Socket缓冲区。

    ```java
    @Override
    protected void doWrite(ChannelOutboundBuffer in) throws Exception {
      
      //1. 获取自旋锁自旋次数
      int writeSpinCount = config().getWriteSpinCount();
      do {
        Object msg = in.current();
        if (msg == null) {
          // Wrote all messages.
          clearOpWrite();
          // Directly return here so incompleteWrite(...) is not called.
          return;
        }
        
        //2. 
        writeSpinCount -= doWriteInternal(in, msg);
      } while (writeSpinCount > 0);
    
      
      //3.
      incompleteWrite(writeSpinCount < 0);
    }
    ```

    * 第一，根据配置获取自旋锁的次数 writeSpinCount。那么你的疑问就来了，这个自旋锁的次数主要是用来干什么的呢？当我们向 Socket 底层写数据的时候，如果每次要写入的数据量很大，是不可能一次将数据写完的，所以只能分批写入。Netty 在不断调用执行写入逻辑的时候，EventLoop 线程可能一直在等待，这样有可能会阻塞其他事件处理。所以这里自旋锁的次数相当于控制一次写入数据的最大的循环执行次数，如果超过所设置的自旋锁次数，那么写操作将会被暂时中断。
    * 第二，根据自旋锁次数重复调用 doWriteInternal 方法发送数据，每成功发送一次数据，自旋锁的次数 writeSpinCount 减 1，当 writeSpinCount 耗尽，那么 doWrite 操作将会被暂时中断。doWriteInternal 的源码涉及 JDK NIO 底层，在这里我们不再深入展开，它的主要作用在于删除缓存中的链表节点以及调用底层 API 发送数据
    * 第三，调用 incompleteWrite 方法确保数据能够全部发送出去，因为自旋锁次数的限制，可能数据并没有写完，所以需要继续 OP_WRITE 事件；如果数据已经写完，清除 OP_WRITE 事件即可。

* 总结

  * writeAndFlush 属于出站操作，它是从 Pipeline 的 Tail 节点开始进行事件传播，一直向前传播到 Head 节点。不管在 write 还是 flush 过程，Head 节点都中扮演着重要的角色。
  * write 方法并没有将数据写入 Socket 缓冲区，只是将数据写入到 ChannelOutboundBuffer 缓存中，ChannelOutboundBuffer 缓存内部是由单向链表实现的。
  * flush 方法才最终将数据写入到 Socket 缓冲区。





